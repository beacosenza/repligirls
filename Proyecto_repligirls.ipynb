{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a043042-501c-4f39-a99e-29c7dcafecad",
   "metadata": {},
   "source": [
    "# Estudio de evolución temporal de aftershocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f392419-f2b7-4ee2-b966-d02cf0479712",
   "metadata": {},
   "source": [
    "Descripción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbfd05-b248-4b25-ae76-4528b898c62e",
   "metadata": {},
   "source": [
    "## 1. Descargar los datos\n",
    "\n",
    "link de google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f44f46-7fe7-4c7e-886f-eeec857b92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/1Vh6umk8AlTCU5XEdpiRRjpy8N9gl3li0/view?usp=share_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a177bd0-f7d5-46ab-a011-6355ea6d0551",
   "metadata": {},
   "source": [
    "Para bajarlo se usa un link modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c32476-d3e3-4157-9925-fcc2943033db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdown https://drive.google.com/uc?id=1Vh6umk8AlTCU5XEdpiRRjpy8N9gl3li0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b7e6a-8274-4771-b0d1-8604382c610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Descomprimir el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75737eb9-3f8c-46fd-b2de-885565732077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip SPUD_bundle_2023-03-28T14.29.00.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b359d89f-ebaa-45cb-8957-d58bac950526",
   "metadata": {},
   "source": [
    "## 2. Importar paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e816d98-4645-46f1-8b28-c5b39b42ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import fnmatch\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "#import pygmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8b62d-390b-4d4f-8f73-1d4a9363307f",
   "metadata": {},
   "source": [
    "## 3. Crear directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac1b63-3fda-4d9b-a70a-2c9fb3deaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir figs_num_time\n",
    "!mkdir figs_mag_time\n",
    "!mkdir figs_depth_time\n",
    "!mkdir figs_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86826a29-c537-47ae-8c85-6ee3707c9975",
   "metadata": {},
   "source": [
    "## 4. Leer y limpiar archivos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f260e4aa-b9b6-4f31-9784-7c0efccc6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listar archivos\n",
    "!rm SPUD_bundle_2023-03-28T14.29.00/After*/*copy.txt\n",
    "dir_path=\"SPUD_bundle_2023-03-28T14.29.00\"\n",
    "list_files=[]\n",
    "for file_dir in glob.glob(dir_path + \"/**\", recursive=True):\n",
    "     if file_dir.endswith(\".txt\"):\n",
    "         list_files.append(file_dir)\n",
    "\n",
    "#print(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b73f4f71-5ea9-41ba-9db1-41379f209eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer archivos y limpiarlos\n",
    "for tx_file in list_files:\n",
    "    agencies=[\",us\",\",US\",\",GCMT\",\",guc\",\",NEIC\",\";NEIC\",\",ISC\",\",IDC\",\",EIDC\",\",CASC\",\",CADCG\",\",SJS\",\",SSNC\",\",MEX\",\",IBQ\",\",IGQ\",\",TRN\",\",TAC\",\",SSS\",\",INET\",\",UVC\",\",RSMAC\",\",SCB\",\",GUC\",\",NEIS\",\",LIM\",\",SNET\",\",SDD\",\",UNM\",\",SJA\",\"JB\"]\n",
    "    mags=[\"|mb,\",\"|MW,\",\"|Mww,\",\"|mww,\",\"|MWR,\",\"|md,\",\"|,\",\"|ML,\",\"|MB,\",\"|MWW,\",\"|MS,\",\"|Mwr,\",\"|mbtmp,\",\"|MD,\",\"|mw,\",\"|mL,\",\"|MSZ,\",\"|MWB,\",\"|mb_Lg,\",\"|mb1mx,\"]\n",
    "    with open(tx_file,'r') as data:\n",
    "        plaintext=data.read()\n",
    "    for sust in agencies:\n",
    "        plaintext=plaintext.replace(sust,\"\")\n",
    "    for sust in mags:\n",
    "        plaintext=plaintext.replace(sust,\"|\")\n",
    "    with open(tx_file[:-4]+\"_copy.txt\", 'w') as f:\n",
    "        f.write(plaintext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813b9f7-2677-4018-af8f-1ea488d8ebbf",
   "metadata": {},
   "source": [
    "## 4. Crear data frame y hacer gráficas de aftershocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36f874-7c80-405b-9d68-ac1cfac8ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear data frame para cada archivo\n",
    "!rm figs_num_time/*\n",
    "!rm figs_mag_time/*\n",
    "!rm figs_depth_time/*\n",
    "!rm figs_comb/*\n",
    "p=[]\n",
    "lat=[]\n",
    "mag=[]\n",
    "a_s=[]\n",
    "#fec=[]\n",
    "for tx_file in list_files:\n",
    "    ex1='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_9762033/1995.10.03.01.51.EventsList.txt'\n",
    "    ex2='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_9754820/2007.11.14.15.40.EventsList.txt'\n",
    "    ex3='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_11519080/2016.04.16.23.58.EventsList.txt'\n",
    "    ex4='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_9753523/1994.06.09.00.33.EventsList.txt'\n",
    "    ex5='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_9759503/1997.01.23.02.15.EventsList.txt'\n",
    "    ex6='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_9758029/2014.04.18.14.27.EventsList.txt'\n",
    "    ex7='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_9762691/2011.01.01.09.56.EventsList.txt'\n",
    "    ex8='SPUD_bundle_2023-03-28T14.29.00/Aftershocks_9761373/1998.01.30.12.16.EventsList.txt'\n",
    "    if (tx_file!=ex1) & (tx_file!=ex2) & (tx_file!=ex3) & (tx_file!=ex4) & (tx_file!=ex5) & (tx_file!=ex6) & (tx_file!=ex7) & (tx_file!=ex8):\n",
    "        df = pd.read_csv(tx_file[:-4]+\"_copy.txt\", sep=\"|\", header=None)\n",
    "        df.columns =['Code', 'Date', 'Latitude', 'Longitude', 'Depth', 'catalog','catalog 2', 'catalog 3','magnitude', 'location']\n",
    "        df[['fecha', 'tiempo']] = df['Date'].str.split(' ', 1, expand=True)\n",
    "        df[['anio', 'mes', 'dia']] = df['fecha'].str.split('/', expand=True)\n",
    "        df[['hora', 'minuto', 'segundo']] = df['tiempo'].str.split(':', expand=True)\n",
    "        df.sort_values(by=['magnitude'], inplace=True, ascending=False)\n",
    "        df=df.reset_index(drop=True)\n",
    "        df['anio'] = df['anio'].astype('int')\n",
    "        df['mes'] = df['mes'].astype('int')\n",
    "        df['dia'] = df['dia'].astype('int')\n",
    "        df['hora'] = df['hora'].astype('int')\n",
    "        df['minuto'] = df['minuto'].astype('int')\n",
    "        df['segundo'] = df['segundo'].astype('float64')\n",
    "        \n",
    "        #extraer información del mainshock\n",
    "        main_year=df.loc[0,'anio']\n",
    "        main_month=df.loc[0,'mes']\n",
    "        main_day=df.loc[0,'dia']\n",
    "        main_hour=df.loc[0,'hora']\n",
    "        main_minute=df.loc[0,'minuto']\n",
    "        main_sec=df.loc[0,'segundo']\n",
    "        main_loc=df.loc[0,'location']\n",
    "        main_mag=df.loc[0,'magnitude']\n",
    "        main_lat=df.loc[0,'Latitude']\n",
    "        main_date=df.loc[0,'fecha']\n",
    "        d_bis=[0,31,60,91,121,152,182,213,244,274,305,335]\n",
    "        d_norm=[0,31,59,90,120,151,181,212,243,273,304,334]\n",
    "        nmes=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "        if (np.mod(main_year,4)==0):\n",
    "            tyear=(main_year//4-1)*366+(main_year-main_year//4)*365\n",
    "            tmonth=d_bis[nmes.index(main_month)]\n",
    "        else:\n",
    "            tyear=(main_year//4)*366+(main_year-1-main_year//4)*365\n",
    "            tmonth=d_norm[nmes.index(main_month)]\n",
    "        #tiempo del mainshock\n",
    "        t0=main_sec + 60*main_minute + 3600*main_hour + 24*3600*(main_day-1) + tmonth*24*3600 + tyear*24*3600\n",
    "\n",
    "        #calcular el tiempo de ocurrencia de los aftershocks después del mainshock\n",
    "        df[\"t\"]=np.nan\n",
    "        #anio no bisiesto\n",
    "        for ind in range(12):\n",
    "            cond=(df['mes'] == nmes[ind]) & (np.mod(df['anio'],4) != 0)\n",
    "            t_true=df[\"segundo\"] + 60*df[\"minuto\"] + 3600*df[\"hora\"] + 24*3600*(df[\"dia\"]-1) + d_norm[ind]*24*3600+((df.anio//4)*366+(df.anio-df.anio//4-1)*365)*24*3600 - t0\n",
    "            df[\"t\"]=np.where(cond,t_true,df[\"t\"])\n",
    "        #anio bisiesto\n",
    "        for ind in range(12):\n",
    "            cond=(df['mes'] == nmes[ind]) & (np.mod(df['anio'],4) == 0)\n",
    "            t_true=df[\"segundo\"] + 60*df[\"minuto\"] + 3600*df[\"hora\"] + 24*3600*(df[\"dia\"]-1) + d_bis[ind]*24*3600+((df.anio//4-1)*366+(df.anio-df.anio//4)*365)*24*3600 - t0\n",
    "            df['t']=np.where(cond,t_true,df['t'])\n",
    "            \n",
    "        #variación del número de aftershocks en el tiempo\n",
    "        size=df.t.count()-1\n",
    "        if (size>=50):\n",
    "            print(size, main_loc, main_day, main_month, main_year, main_mag)\n",
    "            interv=24*3600 #tamaño del intervalo (1 día)\n",
    "            tmax=df['t'].max() #tiempo de la última réplica\n",
    "            bot=0 #valor inicial del límite inferior del intervalo\n",
    "            n=int(np.ceil(tmax / interv)) #número de intervalos\n",
    "            t=[] #número de días\n",
    "            a_shock=[] #cantidad de réplicas\n",
    "\n",
    "            #llenado de las listas con el tiempo y el número de réplicas\n",
    "            for num in range(1,n+1):\n",
    "                top=interv*num\n",
    "                check=df.t[(df.t>bot) & (df.t<=top)].count()\n",
    "                if check > 0:\n",
    "                    a_shock.append(df.t[(df.t>bot) & (df.t<=top)].count())\n",
    "                    t.append(num)\n",
    "                bot=top\n",
    "    \n",
    "            #definición de modelo de Omori para ajustar la curva\n",
    "            def model_f(t,k,c,p):\n",
    "                return k/(c+t)**p\n",
    "\n",
    "            #ajuste de curva\n",
    "            popt, pcov = curve_fit(model_f, t, a_shock)            \n",
    "            k_opt, c_opt, p_opt = popt #parámetros del modelo\n",
    "            \n",
    "            #llenado de listas para análisis posterior de variaciones de\n",
    "            p.append(p_opt)\n",
    "            lat.append(main_lat)\n",
    "            mag.append(main_mag)\n",
    "            a_s.append(size)\n",
    "            #fec.append(main_date)\n",
    "\n",
    "            #puntos para el modelo\n",
    "            x_model = np.linspace(min(t), max(t), 100)\n",
    "            y_model = model_f(x_model, k_opt, c_opt, p_opt) \n",
    " \n",
    "            #gráfica de decaimiento\n",
    "            plt.plot(t,a_shock,'o')\n",
    "            plt.plot(x_model, y_model,'r')\n",
    "            plt.xlim((0))\n",
    "            plt.ylim((0))\n",
    "            plt.xlabel(\"Días después del terremoto\")\n",
    "            plt.ylabel(\"Número de réplicas\")\n",
    "            title=\"M\"+str(main_mag)+\" EARTHQUAKE \"+main_loc+\", \"+str(int(main_day))+\"-\"+str(int(main_month))+\"-\"+str(int(main_year))+\" (\"+str(size)+\" réplicas)\"\n",
    "            plt.title(title)\n",
    "            plt.text(4.5, max(a_shock)-max(a_shock)/5,\n",
    "                     'k='+str(round(k_opt,2))+', c='+str(round(c_opt,2))+', p='+str(round(p_opt,2)), \n",
    "                     horizontalalignment='left',verticalalignment='bottom'\n",
    "                    )\n",
    "            plt.savefig('figs_num_time/num_time_'+main_loc+\", \"+str(int(main_day))+\"-\"+str(int(main_month))+\"-\"+str(int(main_year)),bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "        #grafica de magnitud vs tiempo\n",
    "            plt.figure(figsize=(7.6,4))\n",
    "            plt.scatter(df.t[(df.t>=0)]/interv,df.magnitude[(df.t>=0)],s=df.magnitude[(df.t>=0)]*30,c=df.Depth[(df.t>=0)],alpha=0.5)\n",
    "            plt.xlabel(\"Días después del terremoto\")\n",
    "            plt.ylabel(\"Magnitud de las réplicas\")\n",
    "            plt.colorbar(label='profundidad (km)')\n",
    "            plt.title(title)\n",
    "            plt.savefig('figs_mag_time/mag_time_'+main_loc+\", \"+str(int(main_day))+\"-\"+str(int(main_month))+\"-\"+str(int(main_year)),bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        #grafica combinada\n",
    "            fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15, 4),gridspec_kw={'width_ratios': [8,10],'height_ratios':[1]})\n",
    "            fig.suptitle(title)\n",
    "            ax1.plot(t,a_shock,'o')\n",
    "            ax1.plot(x_model, y_model,'r')\n",
    "            ax1.set_xlim((0))\n",
    "            ax1.set_ylim((0))\n",
    "            ax1.set_xlabel(\"Días después del terremoto\")\n",
    "            ax1.set_ylabel(\"Número de réplicas\")\n",
    "            ax1.text(4.5, max(a_shock)-max(a_shock)/5,\n",
    "                     'k='+str(round(k_opt,2))+', c='+str(round(c_opt,2))+', p='+str(round(p_opt,2)), \n",
    "                     horizontalalignment='left',verticalalignment='bottom'\n",
    "                    )\n",
    "            pcm=ax2.scatter(df.t[(df.t>=0)]/interv,df.magnitude[(df.t>=0)],s=df.magnitude[(df.t>=0)]*30,c=df.Depth[(df.t>=0)],alpha=0.5)\n",
    "            ax2.set_xlabel(\"Días después del terremoto\")\n",
    "            ax2.set_ylabel(\"Magnitud de las réplicas\")\n",
    "            ax=ax2\n",
    "            fig.colorbar(pcm,ax=ax2,label='profundidad (km)')\n",
    "            plt.savefig('figs_comb/comb_'+main_loc+\", \"+str(int(main_day))+\"-\"+str(int(main_month))+\"-\"+str(int(main_year)),bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "        #grafica de profundidad vs tiempo\n",
    "            plt.figure(figsize=(7.6,4))\n",
    "            plt.scatter(df.t[(df.t>=0)]/interv,df.Depth[(df.t>=0)],s=df.magnitude[(df.t>=0)]*15,c=df.magnitude[(df.t>=0)],alpha=0.5)\n",
    "            plt.xlabel(\"Días después del terremoto\")\n",
    "            plt.ylabel(\"Profundidad de las réplicas\")\n",
    "            plt.colorbar(label='magnitud')\n",
    "            plt.title(\"M\"+str(main_mag)+\" EARTHQUAKE \"+main_loc+\", \"+str(int(main_day))+\"-\"+str(int(main_month))+\"-\"+str(int(main_year))+\" (\"+str(size)+\" réplicas)\")\n",
    "            plt.savefig('figs_depth_time/depth_time_'+main_loc+\", \"+str(int(main_day))+\"-\"+str(int(main_month))+\"-\"+str(int(main_year)),bbox_inches='tight')\n",
    "            plt.show()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c3941-9483-4578-b12e-5334c9d5905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variaciones de p\n",
    "#eliminar eventos repetidos con menos replicas [8 10 13 19]\n",
    "for ind in [8, 9, 11, 16]:\n",
    "    del p[ind]\n",
    "    del lat[9]\n",
    "    del a_s[11]\n",
    "    del mag[11]\n",
    "#gráficas\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15, 4))\n",
    "fig.suptitle(\"Variación de la constante de decaimiento p\")\n",
    "ax1.plot(llim,plim_u,'k--')\n",
    "ax1.plot(llim,plim_d,'k--')\n",
    "pcm=ax1.scatter(lat, p,s=70,c=a_s,alpha=0.5)\n",
    "fig.colorbar(pcm,ax=ax1,label='Número de réplicas')\n",
    "ax1.set_xlabel(\"Latitud\")\n",
    "ax1.set_ylabel(\"p\")\n",
    "ax2.plot(mlim,plim_u,'k--')\n",
    "ax2.plot(mlim,plim_d,'k--')\n",
    "pcm=ax2.scatter(mag, p,s=70,c=a_s,alpha=0.5)\n",
    "ax2.set_xlabel(\"Magnitud\")\n",
    "ax2.set_ylabel(\"p\")\n",
    "fig.colorbar(pcm,ax=ax2,label='Número de réplicas')\n",
    "plt.savefig('p_comp',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d944a-18a1-4135-9fb0-270492e69973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected earthquakes\n",
    "print(main_lon,main_lat,main_depth,main_mag, main_date, main_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839db3e8-c352-48d2-90f9-dc6b986d10f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82bb59-6929-439e-b9a2-e923776796e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9d272-0223-41db-b1fe-8d00ff021e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a088154-c6cd-4755-923c-5d1943d7d122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoCo",
   "language": "python",
   "name": "coco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
